{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Sentence Similarity.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "spLDhsInWo7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGP7kVe-Wo7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = list(pd.read_csv('yelp.csv')['text'])\n",
        "\n",
        "# Print the first review from t\n",
        "print(docs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPnWyL2Wo7R",
        "colab_type": "text"
      },
      "source": [
        "# Context-free sentence similarity detection: tf-idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edlLNwcEWo7V",
        "colab_type": "text"
      },
      "source": [
        "tf-idf stands for: Term Frequency - Inverse Document Frequency\n",
        "\n",
        "It is a metric to determine how similar one term is to the terms found in a specific document from the set of avaliable documents. It is calculated via the following equation:\n",
        "\n",
        "**tfidf(t, d, D) = tf(t, d) * idf(t, D)**\n",
        "\n",
        "where:\n",
        "    \n",
        "| Variable | Meaning                                                    |\n",
        "| -------- | ---------------------------------------------------------- |\n",
        "| t        | The term to find                                           |\n",
        "| d        | The document we are referring to find the term's frequency |\n",
        "| D        | Set of all documents                                       |\n",
        "| tf()     | Function to calculate the term frequency                   |\n",
        "| idf()    | Function to calcualte the inverse document frequency       |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5zrIqK0Wo7W",
        "colab_type": "text"
      },
      "source": [
        "## Calculating term frequency: tf(t, d)\n",
        "\n",
        "Tem Frequency refers to how often a specific term appears in a specific document. The simpliest method is by counting the number of times the term appears in the document. Let this raw count be denoted as $f_{t,d}$. By default, `gensim.models.TfidfModel` calculates the term frequency weighting using this approach. Below is basic pseudocode to represent how $f_{t,d}$ could possibly be implemented:\n",
        "\n",
        "```python\n",
        "def raw_count(t, d):\n",
        "    count = 0\n",
        "    for term in d:\n",
        "        if t == term:\n",
        "            count += 1\n",
        "    return count\n",
        "````\n",
        "\n",
        "However, the document length could have an impact on the bias. By dividing $f_{t,d}$ by the most frequent term in the document, it provides a more normalized frequency values across serveral documents. To balance small documents, we can provide an offest to account for their size. Below is one implementation of this augmented term frequency function:\n",
        "\n",
        "$$ 0.5 + \\frac{f_{t,d}}{\\max\\limits_{t' \\in d}(f_{t',d})} $$\n",
        "\n",
        "`gensim.models.TfidfModel` has the ability to change its term frequency weightings. See the following url for the class documentation:\n",
        "\n",
        "> https://radimrehurek.com/gensim/models/tfidfmodel.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJwZOpojWo7X",
        "colab_type": "text"
      },
      "source": [
        "## Calculating Inverse Document Frequency: idf(t, D)\n",
        "\n",
        "Inverse Document Frequency is a huerisitc that measures how much information the term provides found in all given documents. One possible way to define inverse document frequency is the following:\n",
        "\n",
        "$$ \\log \\frac{|D|}{|\\{d | d \\in D, t \\in d \\}|} $$\n",
        "\n",
        "where $|D|$ is the number of documents and $|\\{d | d \\in D, t \\in d\\}|$ is the number of documents that the term appears in.\n",
        "\n",
        "Examing this function, we can notice the inverse relationship between idf and the number of occurrence of the document. As there is less times the term appears, the higher the idf hueristic gets.\n",
        "\n",
        "By default, `gensim.models.TfidfModel` uses a function similar to the one above to calculate the inverse document frequency. Just like with term frequency, the class has the ability to change its inverse document frequency weightings.  to See the following url for the class documentation:\n",
        "\n",
        "> https://radimrehurek.com/gensim/models/tfidfmodel.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxZDZqZpWo7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import TfidfModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.similarities import MatrixSimilarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tk6SjxZWo7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenize words in each document\n",
        "\n",
        "#Create a dictionary - assign indices to the words in the documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pDL69toWo7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPwrY3x2Wo7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le3nSKoBWo7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#doc_test = \"The food was terrible. The service was unprofessional\"\n",
        "doc_test = \"I loved this place. The food was great. The staff was professional\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxJLXzkZWo74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBw6OHvfWo78",
        "colab_type": "text"
      },
      "source": [
        "# Context-sensitive sentence similarity detection: word2vec\n",
        "\n",
        "2 possible methodologies to create the word representation:\n",
        "\n",
        "- continuous skip-gram\n",
        "    - Given the middle word, predict the surrounding words.\n",
        "- continuous bag-of-words\n",
        "    - Given the surrounding words, predict the middle word.\n",
        "    \n",
        "In either of the methods listed above, cosine similarity is used to measure sentence similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-D5sIXKWo79",
        "colab_type": "text"
      },
      "source": [
        "## Cosine Similarity\n",
        "\n",
        "To determine the similarity between two documents are similar, we can manipulate the Euclidian Dot Product Formula to generate the following equation for vectors A & B:\n",
        "\n",
        "$$ similarity = abs(\\cos(\\theta)) = abs(\\frac{A \\bullet B}{||A||~||B||})  $$\n",
        "\n",
        "By examining this equation, parallel vectors would have maximum similarity and perpendicular vectors would have 0 similarity between them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzoJNfirWo7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLf9xZ6LWo8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JinKTcCkWo8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfxMMvUvWo8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGHNe0hVWo8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LHFQ3ZAWo8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vBfgjZEWo8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = simple_preprocess(\"I loved the food\".lower())\n",
        "v = model.infer_vector(test_data)\n",
        "\n",
        "sims = model.docvecs.most_similar([v])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLEk3gwTWo8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH5GkLHiWo8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWgHWiFWo8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_list = ['the', 'professional', 'best', 'good', 'bad', 'amazing', 'awful', 'awesome', 'food', 'service']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51T26-2SWo8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acJa9UOTWo8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "colors = ['r', 'g', 'b', 'magenta', 'cyan', 'brown', 'black', 'orange', 'purple', 'yellow']\n",
        "for i in range(10):\n",
        "    pts = X_embedded[10*i:10*i+10]\n",
        "    ax.scatter(pts[:,0], pts[:,1], c=colors[i], cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}